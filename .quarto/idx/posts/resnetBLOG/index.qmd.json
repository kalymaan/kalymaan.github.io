{"title":"Classifying Paintings with a resnet18 CNN","markdown":{"yaml":{"title":"Classifying Paintings with a resnet18 CNN","author":"Kalyan Lakshmanan","date":"2023-08-06","categories":["Computer Vision","Deep Learning"],"image":"wow.jpg"},"headingText":"Classifying Paintings","containsRefs":false,"markdown":"\nThis is my first blog post. Let's see how it goes.\n\n<img src='wow.jpg' width= 50% height= 50%>\n\nI'm currently working my way through Jeremy Howard and Rachel Thomas's [fast.ai course](https://course.fast.ai/). It's really fun and I can't recommend it enough. Watch [this](https://www.youtube.com/watch?v=gGxe2mN3kAg&t=7s) video -- it dispells a lot of the myths regarding deep learning.\n\nMy goals for this blog post are to:\n\n- Get used to blogging and \"personal branding / marketing \nmyself\" without cringing into oblivion.\n\n- Explain how I implemented and deployed an image classifier:\n\n    - Data Collection\n\n    - Model Selection\n\n    - Model Training\n    \n    - Model Deployment\n\n\nNow, for the cool stuff: I've trained and deployed an image classifier application. In theory, it's supposed to accept a picture of a painting and predict what art period/movement it would belong to.\n\n[Here](https://huggingface.co/spaces/kalymaan/art-classfier) is a link to the app.\n\nIt's pretty inaccurate now, I'll get into why later. \n\nIts fun to play around with though.\n\nHere's a painting I made. (Yes I know, I should quit everything and become an artist fulltime. What can I say? I am a true renaissance man. )\n\n<img src= 'otherart/354679114.png' width= 50% height= 50% >\n\nAccording to the application I developed, I'm an [expressionist](https://en.wikipedia.org/wiki/Expressionism). Apparently, I present the world in my subjective view. Wow, I'm so deep.\n\n<img src= 'otherart/myresults.PNG' width= 70% height = 70%>\n\n## Data Collection\n\nI knew that I wanted to classify art. First step, get the labeled data. I thought of two ways:\n\n- Scrape search engines and get it manually. (I will be exploring this in my next version of this application. I'll cover that in a future blog post.)\n- Find a ready made data set.\n\n[Kaggle came to the rescue.](https://www.kaggle.com/datasets/cyanex1702/surreal-symphonies-a-dataset-of-diverse-art)\n\nIt's over 7,000 images of paintings. What's really convenient, is the way in which it is organized. Each art movement/period has its own folder with all the associated images in those folders. This file organization is perfect for getting labels.\n\nNow, there are a lot of issues with this data set as well. If you look at the link above and do just a cursory inspection of the images in each folder, you'll notice a lot of repeated images. I suspect that this will cause some over training. Also, there are way too many categories. I'm no art history expert, but I suspect that there's a lot of overlap with the movements/periods defined in the dataset. \n\nI ignore all those problems and use the data set as is. This is a big reason why the end application isn't that accurate. \n\nIt's ok, I'm planning on making another version in the future.\n\n## Model Selection\n\nThe type of learning this model will be doing is called [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).\n\nBasically image classification is a popular task and many people and organization have already developed pretrained models for image classification. I'll simply use one of those (specifically the [resnet18](https://www.mathworks.com/help/deeplearning/ref/resnet18.html) convolutional neural network) and just train it further on my specific data set to get the behavior that I want. \n\n## Model Training\n\nHere, I'll demonstrate some of the capabilities of some of the fastai api (it's built on top of PyTorch).\n\n<img src=otherart/blogpost1images/1.PNG>\n\nAlong with creating this fantastic course that I'm doing, the fast.ai team have also developed this easy-to-use framework for working in deep learning.\n\nFirst Let's get the data ready for the model. In order to do that, we use fastai's [DataLoaders](https://docs.fast.ai/data.load.html) class. A [DataBlock](https://docs.fast.ai/data.block.html) is a container/template for the DataLoaders.\n\n<img src= otherart/blogpost1images/2.PNG>\n\nHere's an example of 4 images in the validation set.\n\n<img src= otherart/blogpost1images/3.PNG>\n\n<img src= otherart/blogpost1images/4.PNG>\n\nNow let's give the model something the eat.\n\n<img src= otherart/blogpost1images/5.PNG>\n\n<img src= otherart/blogpost1images/6.PNG>\n\nSide Note: I usually do this type of training/prototyping on GPU servers. But I was curious and decided to do it on an old abandoned desktop computer CPU at my house. It made a lot of interesting noises\n\nI can live with a 4% error rate. Maybe just 4 epochs could have sufficed. There's not a huge benefit the model gains between the 4th and 5th one. \n\nLet's look at the top  validation image that the model had trouble predicting.\n\n<img src= otherart/blogpost1images/7.PNG>\n\n<img src= otherart/blogpost1images/8.PNG>\n\nThe model thought that the above image was contemporary art. It's actually modernist.\n\n... I'll forgive the model on this one. \n\nThis is what I was mentioning before. There are a lot of categories that we're dealing with that are very hard to discern between. \n[Here's](https://www.eden-gallery.com/news/modern-art-vs-contemporary-art#:~:text=Modern%20art%20refers%20to%20art%20created%20from%20the%201880s%20up,describes%20current%20works%20of%20art.) a link to an explanation of the difference between modern and contemporary art. It seems like it's just the time it was made. \n\nSo for future iterations of this project, I need to carefully pick categories. Do I pick the categories based on time period, or visual style? I may need an art historian to help me with that because intuitively, I don't think that art movements/periods can be easily categorized like that.\n\nIn any case, now the model is trained, has new muscles, and is ready to show them off. To get it ready, let's turn it into a pickle.\n\n<img src = 'otherart/Pickle_Rick.jpg'>\n\nSee, look how tuned I am with the zeitgeist. I'm hip. I'm cool guy.\n\nLet's export the model into a .pkl file.\n\n<img src= otherart/blogpost1images/9.PNG>\n\n## Model Deployment\n\nI heavily referenced Tanishq Abraham's [blog post](https://www.tanishq.ai/blog/gradio_hf_spaces_tutorial) to deploy this model. Take a look at it. \n\n[Gradio](https://www.gradio.app/guides/quickstart) is an easy way to demo machine learning models and [HuggingFace Spaces](https://huggingface.co/docs/hub/spaces-overview) are equaly easy to use places to host said models.\n\nAfter following the blog post (link above), I was left with [this app](https://huggingface.co/spaces/kalymaan/art-classfier)\n\nNow I'm writing this blog post before I make the website that you are reading this on. By then, I may have already deployed it on this website itself. It may be under \"Projects\" or something. I'm using [Quarto](https://quarto.org/) to build this websit by the way.\n\n## So that's it\n\nThat's my blog post. Honestly, it was a slog to get through, but that's ok. I need to get used to writing these anyways.\n\nIf you have any comments, corrections, questions, concerns, advice, or you want to just troll me, please email me at kalyankumar@outlook.com. \n\nOk thanks bye.\n","srcMarkdownNoYaml":"\nThis is my first blog post. Let's see how it goes.\n\n<img src='wow.jpg' width= 50% height= 50%>\n\nI'm currently working my way through Jeremy Howard and Rachel Thomas's [fast.ai course](https://course.fast.ai/). It's really fun and I can't recommend it enough. Watch [this](https://www.youtube.com/watch?v=gGxe2mN3kAg&t=7s) video -- it dispells a lot of the myths regarding deep learning.\n\nMy goals for this blog post are to:\n\n- Get used to blogging and \"personal branding / marketing \nmyself\" without cringing into oblivion.\n\n- Explain how I implemented and deployed an image classifier:\n\n    - Data Collection\n\n    - Model Selection\n\n    - Model Training\n    \n    - Model Deployment\n\n## Classifying Paintings\n\nNow, for the cool stuff: I've trained and deployed an image classifier application. In theory, it's supposed to accept a picture of a painting and predict what art period/movement it would belong to.\n\n[Here](https://huggingface.co/spaces/kalymaan/art-classfier) is a link to the app.\n\nIt's pretty inaccurate now, I'll get into why later. \n\nIts fun to play around with though.\n\nHere's a painting I made. (Yes I know, I should quit everything and become an artist fulltime. What can I say? I am a true renaissance man. )\n\n<img src= 'otherart/354679114.png' width= 50% height= 50% >\n\nAccording to the application I developed, I'm an [expressionist](https://en.wikipedia.org/wiki/Expressionism). Apparently, I present the world in my subjective view. Wow, I'm so deep.\n\n<img src= 'otherart/myresults.PNG' width= 70% height = 70%>\n\n## Data Collection\n\nI knew that I wanted to classify art. First step, get the labeled data. I thought of two ways:\n\n- Scrape search engines and get it manually. (I will be exploring this in my next version of this application. I'll cover that in a future blog post.)\n- Find a ready made data set.\n\n[Kaggle came to the rescue.](https://www.kaggle.com/datasets/cyanex1702/surreal-symphonies-a-dataset-of-diverse-art)\n\nIt's over 7,000 images of paintings. What's really convenient, is the way in which it is organized. Each art movement/period has its own folder with all the associated images in those folders. This file organization is perfect for getting labels.\n\nNow, there are a lot of issues with this data set as well. If you look at the link above and do just a cursory inspection of the images in each folder, you'll notice a lot of repeated images. I suspect that this will cause some over training. Also, there are way too many categories. I'm no art history expert, but I suspect that there's a lot of overlap with the movements/periods defined in the dataset. \n\nI ignore all those problems and use the data set as is. This is a big reason why the end application isn't that accurate. \n\nIt's ok, I'm planning on making another version in the future.\n\n## Model Selection\n\nThe type of learning this model will be doing is called [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).\n\nBasically image classification is a popular task and many people and organization have already developed pretrained models for image classification. I'll simply use one of those (specifically the [resnet18](https://www.mathworks.com/help/deeplearning/ref/resnet18.html) convolutional neural network) and just train it further on my specific data set to get the behavior that I want. \n\n## Model Training\n\nHere, I'll demonstrate some of the capabilities of some of the fastai api (it's built on top of PyTorch).\n\n<img src=otherart/blogpost1images/1.PNG>\n\nAlong with creating this fantastic course that I'm doing, the fast.ai team have also developed this easy-to-use framework for working in deep learning.\n\nFirst Let's get the data ready for the model. In order to do that, we use fastai's [DataLoaders](https://docs.fast.ai/data.load.html) class. A [DataBlock](https://docs.fast.ai/data.block.html) is a container/template for the DataLoaders.\n\n<img src= otherart/blogpost1images/2.PNG>\n\nHere's an example of 4 images in the validation set.\n\n<img src= otherart/blogpost1images/3.PNG>\n\n<img src= otherart/blogpost1images/4.PNG>\n\nNow let's give the model something the eat.\n\n<img src= otherart/blogpost1images/5.PNG>\n\n<img src= otherart/blogpost1images/6.PNG>\n\nSide Note: I usually do this type of training/prototyping on GPU servers. But I was curious and decided to do it on an old abandoned desktop computer CPU at my house. It made a lot of interesting noises\n\nI can live with a 4% error rate. Maybe just 4 epochs could have sufficed. There's not a huge benefit the model gains between the 4th and 5th one. \n\nLet's look at the top  validation image that the model had trouble predicting.\n\n<img src= otherart/blogpost1images/7.PNG>\n\n<img src= otherart/blogpost1images/8.PNG>\n\nThe model thought that the above image was contemporary art. It's actually modernist.\n\n... I'll forgive the model on this one. \n\nThis is what I was mentioning before. There are a lot of categories that we're dealing with that are very hard to discern between. \n[Here's](https://www.eden-gallery.com/news/modern-art-vs-contemporary-art#:~:text=Modern%20art%20refers%20to%20art%20created%20from%20the%201880s%20up,describes%20current%20works%20of%20art.) a link to an explanation of the difference between modern and contemporary art. It seems like it's just the time it was made. \n\nSo for future iterations of this project, I need to carefully pick categories. Do I pick the categories based on time period, or visual style? I may need an art historian to help me with that because intuitively, I don't think that art movements/periods can be easily categorized like that.\n\nIn any case, now the model is trained, has new muscles, and is ready to show them off. To get it ready, let's turn it into a pickle.\n\n<img src = 'otherart/Pickle_Rick.jpg'>\n\nSee, look how tuned I am with the zeitgeist. I'm hip. I'm cool guy.\n\nLet's export the model into a .pkl file.\n\n<img src= otherart/blogpost1images/9.PNG>\n\n## Model Deployment\n\nI heavily referenced Tanishq Abraham's [blog post](https://www.tanishq.ai/blog/gradio_hf_spaces_tutorial) to deploy this model. Take a look at it. \n\n[Gradio](https://www.gradio.app/guides/quickstart) is an easy way to demo machine learning models and [HuggingFace Spaces](https://huggingface.co/docs/hub/spaces-overview) are equaly easy to use places to host said models.\n\nAfter following the blog post (link above), I was left with [this app](https://huggingface.co/spaces/kalymaan/art-classfier)\n\nNow I'm writing this blog post before I make the website that you are reading this on. By then, I may have already deployed it on this website itself. It may be under \"Projects\" or something. I'm using [Quarto](https://quarto.org/) to build this websit by the way.\n\n## So that's it\n\nThat's my blog post. Honestly, it was a slog to get through, but that's ok. I need to get used to writing these anyways.\n\nIf you have any comments, corrections, questions, concerns, advice, or you want to just troll me, please email me at kalyankumar@outlook.com. \n\nOk thanks bye.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"slate","title-block-banner":true,"title":"Classifying Paintings with a resnet18 CNN","author":"Kalyan Lakshmanan","date":"2023-08-06","categories":["Computer Vision","Deep Learning"],"image":"wow.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}